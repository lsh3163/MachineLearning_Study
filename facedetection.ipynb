{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facedetection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsh3163/MachineLearning_Study/blob/master/facedetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "q227OqbEa35O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Face Detection using OpenCV\n",
        "## 얼굴 옆면을 앞면으로 만들기 위한 사전 작업\n",
        "**_Estimated completion time: 60 minutes_**\n",
        "순서는 아래와 같다.\n",
        "  1. Colab 환경설정\n",
        "  2. 얼굴 파일 불러들인 후 읽기\n",
        "  3. 모자이크 처리(예시)"
      ]
    },
    {
      "metadata": {
        "id": "pYjGegzLbzde",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Colab 환경설정\n",
        "* 구글 드라이브 사용"
      ]
    },
    {
      "metadata": {
        "id": "6rtRYlHXbxxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "8c49275e-c871-46cb-b9c7-f9ca9f3b2dcf"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 22280 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.0-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8St2gsa1dEr-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* 디렉토리 만들고 mount 하기"
      ]
    },
    {
      "metadata": {
        "id": "WAjlUOOVbQZ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive \n",
        "!google-drive-ocamlfuse drive "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V01R5nS5dHK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6457985-9b31-4245-c5b7-2501b405f02d"
      },
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HbA8z7tKdL6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "b811fae5-e13c-4fc8-c7ec-d441fc7a7083"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'일화실(1)_증류수지랄.odt'\n",
            "'취업준비생 AI인재 양성 심화과정 4기 신청서(이승현).pdf'\n",
            "'Art Generation with Neural Style Transfer - v1.ipynb'\n",
            "'Autonomous driving application - Car detection - v1.ipynb'\n",
            "'Colab Notebooks'\n",
            "'Convolution model - Step by Step - v1.ipynb'\n",
            "'div 1 대테러 작전.odt'\n",
            "'div 1 문자의 값어치.odt'\n",
            "'Face Recognition for the Happy House - v2.ipynb'\n",
            " generative_model_1.pdf\n",
            "'Keras - Tutorial - Happy House v1.ipynb'\n",
            "'Machine Learning Yearning (Andrew Ng, complete draft 1-58)'\n",
            " 알.ods\n",
            "'일물실_버니어 캘리퍼스.odt'\n",
            " README.md\n",
            "'Residual Networks - v1.ipynb'\n",
            " test_images\n",
            "'Thurs.1-2교시 이승현.odt'\n",
            "'UCPC 참가서(제출용)(응답).ods'\n",
            "'UCPC 참가서(제출용).zip'\n",
            " Untitled0.ipynb\n",
            " yolov3.ipynb\n",
            "'제목 없는 설문지.zip'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WHPhNY8RdNYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d7177f41-73a3-4d3f-db58-455ba6b8ca46"
      },
      "cell_type": "code",
      "source": [
        "cd 'Colab Notebooks'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "30NyfpGudS3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "258a19b1-49d9-4f12-b5cf-c112ea6bd9d8"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cats_and_dogs\t\t\t\t       labelImg\n",
            " CNN.ipynb\t\t\t\t       pix2pix_keras.ipynb\n",
            "'Convolution model - Application - v1.ipynb'   pytorch1.ipynb\n",
            "'CycleGAN의 사본'\t\t\t       pytorch2.ipynb\n",
            " CycleGan.ipynb\t\t\t\t      'PyTorch-YOLOv3.ipynb의 사본'\n",
            " data_loading_tutorial.ipynb\t\t       realstyle.ipynb\n",
            " Face_Detection\t\t\t\t       Toycode\n",
            " GAN_tutorial.ipynb\t\t\t       Untitled0.ipynb\n",
            "'Keras(5)_ComputerVision.ipynb'\t\t       YOLOv2.ipynb\n",
            "'keras(8_3)styletrans.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GJ-YPlN6dT6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4015c002-8bcd-4bad-b38e-749cd3323942"
      },
      "cell_type": "code",
      "source": [
        "cd Face_Detection"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Colab Notebooks/Face_Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H_nvD3WFdZ6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ba5f030-1c24-407a-c432-a03d975214db"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exo.JPG  facedetection.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W1ekiXZMdhvW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* opencv 설치"
      ]
    },
    {
      "metadata": {
        "id": "esVSswsYdazl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b05be13c-d3e1-40c8-b134-5e2e29879ed5"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install opencv-python"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B5SbFW4ldp-_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. 얼굴 이미지 인식 후 읽기"
      ]
    },
    {
      "metadata": {
        "id": "_eJ_NmIFdmRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f2ede48-b77c-47c5-8b0b-4015837f1154"
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import sys\n",
        "\n",
        "image_file = './exo.JPG'\n",
        "\n",
        "# cascade 파일 지정하기 -> 눈도 detection 가능\n",
        "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
        "\n",
        "# 이미지 파일 읽어 들이기\n",
        "image = cv2.imread(image_file)\n",
        "\n",
        "# 그레이스 스케일로 변환하기\n",
        "image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 얼굴인식 특징 파일 읽어 들이기\n",
        "cascade = cv2.CascadeClassifier(cascade_file)\n",
        "\n",
        "# 얼굴인식 실행하기\n",
        "face_list = cascade.detectMultiScale(image_gs, scaleFactor=1.1, minNeighbors=1, minSize=(150, 150))\n",
        "\n",
        "if len(face_list) > 0:\n",
        "  # 인식한 부분 표시하기\n",
        "  print(face_list)\n",
        "  color = (0,100,100)\n",
        "  for face in face_list:\n",
        "    x, y, w, h = face\n",
        "    # 파일로 출력하기\n",
        "    cv2.rectangle(image, (x,y), (x+w, y+h), color, thickness=4)\n",
        "  cv2.imwrite(\"facedetection_output1.PNG\", image)\n",
        "else:\n",
        "  print(\"No face\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[209 107 185 185]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F1bsd_V0f_4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "330474e1-ae13-49aa-8c68-3103c4061983"
      },
      "cell_type": "code",
      "source": [
        "image_file = './target.JPG'\n",
        "\n",
        "# cascade 파일 지정하기 -> 눈도 detection 가능\n",
        "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
        "\n",
        "# 이미지 파일 읽어 들이기\n",
        "image = cv2.imread(image_file)\n",
        "\n",
        "# 그레이스 스케일로 변환하기\n",
        "image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 얼굴인식 특징 파일 읽어 들이기\n",
        "cascade = cv2.CascadeClassifier(cascade_file)\n",
        "\n",
        "# 얼굴인식 실행하기\n",
        "face_list = cascade.detectMultiScale(image_gs, scaleFactor=1.1, minNeighbors=1, minSize=(150, 150))\n",
        "\n",
        "if len(face_list) > 0:\n",
        "  # 인식한 부분 표시하기\n",
        "  print(face_list)\n",
        "  color = (0,100,100)\n",
        "  for face in face_list:\n",
        "    x, y, w, h = face\n",
        "    # 파일로 출력하기\n",
        "    cv2.rectangle(image, (x,y), (x+w, y+h), color, thickness=4)\n",
        "  cv2.imwrite(\"facedetection_output2.PNG\", image)\n",
        "else:\n",
        "  print(\"No face\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No face\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "30gCX60ogpR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b17c24f-92f8-4ff8-bf6c-b0e96b33ddce"
      },
      "cell_type": "code",
      "source": [
        "image_file = './target2.JPG'\n",
        "\n",
        "# cascade 파일 지정하기 -> 눈도 detection 가능\n",
        "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
        "\n",
        "# 이미지 파일 읽어 들이기\n",
        "image = cv2.imread(image_file)\n",
        "\n",
        "# 그레이스 스케일로 변환하기\n",
        "image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 얼굴인식 특징 파일 읽어 들이기\n",
        "cascade = cv2.CascadeClassifier(cascade_file)\n",
        "\n",
        "# 얼굴인식 실행하기\n",
        "face_list = cascade.detectMultiScale(image_gs, scaleFactor=1.1, minNeighbors=1, minSize=(150, 150))\n",
        "\n",
        "if len(face_list) > 0:\n",
        "  # 인식한 부분 표시하기\n",
        "  print(face_list)\n",
        "  color = (0,100,100)\n",
        "  for face in face_list:\n",
        "    x, y, w, h = face\n",
        "    # 파일로 출력하기\n",
        "    cv2.rectangle(image, (x,y), (x+w, y+h), color, thickness=4)\n",
        "  cv2.imwrite(\"facedetection_output2.PNG\", image)\n",
        "else:\n",
        "  print(\"No face\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[118 104 207 207]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}